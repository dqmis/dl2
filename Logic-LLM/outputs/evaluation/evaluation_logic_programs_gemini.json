{
    "gemini-1.0-pro-vision-001": {
        "ProntoQA": {
            "random": {
                "Overall_Accuracy": 0.774,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.774
            },
            "Direct": {
                "Overall_Accuracy": 0.774,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.774
            },
            "CoT": {
                "Overall_Accuracy": 0.774,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.774
            }
        },
        "ProofWriter": {
            "random": {
                "Overall_Accuracy": 0.6126878130217028,
                "Executable_Rate": 0.6444073455759599,
                "Executable_Accuracy": 0.7616580310880829
            },
            "Direct": {
                "Overall_Accuracy": 0.5542570951585977,
                "Executable_Rate": 0.6444073455759599,
                "Executable_Accuracy": 0.7616580310880829
            },
            "CoT": {
                "Overall_Accuracy": 0.6928213689482471,
                "Executable_Rate": 0.6444073455759599,
                "Executable_Accuracy": 0.7616580310880829
            }
        },
        "FOLIO": {
            "random": {
                "Overall_Accuracy": 0.53,
                "Executable_Rate": 0.485,
                "Executable_Accuracy": 0.6804123711340206
            },
            "Direct": {
                "Overall_Accuracy": 0.655,
                "Executable_Rate": 0.48,
                "Executable_Accuracy": 0.6875
            },
            "CoT": {
                "Overall_Accuracy": 0.675,
                "Executable_Rate": 0.485,
                "Executable_Accuracy": 0.6804123711340206
            }
        },
        "LogicalDeduction": {
            "random": {
                "Overall_Accuracy": 0.6133333333333333,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8944444444444445
            },
            "Direct": {
                "Overall_Accuracy": 0.7,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8944444444444445
            },
            "CoT": {
                "Overall_Accuracy": 0.72,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8944444444444445
            }
        },
        "AR-LSAT": {
            "random": {
                "Overall_Accuracy": 0.2217391304347826,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0.20869565217391303,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0.2608695652173913,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        }
    },
    "gemini-1.5-pro-preview-0409": {
        "ProntoQA": {
            "random": {
                "Overall_Accuracy": 0.956,
                "Executable_Rate": 0.964,
                "Executable_Accuracy": 0.9730290456431535
            },
            "Direct": {
                "Overall_Accuracy": 0.962,
                "Executable_Rate": 0.964,
                "Executable_Accuracy": 0.9730290456431535
            },
            "CoT": {
                "Overall_Accuracy": 0.974,
                "Executable_Rate": 0.964,
                "Executable_Accuracy": 0.9730290456431535
            }
        },
        "ProofWriter": {
            "random": {
                "Overall_Accuracy": 0.7466216216216216,
                "Executable_Rate": 0.893581081081081,
                "Executable_Accuracy": 0.8052930056710775
            },
            "Direct": {
                "Overall_Accuracy": 0.7601351351351351,
                "Executable_Rate": 0.893581081081081,
                "Executable_Accuracy": 0.8052930056710775
            },
            "CoT": {
                "Overall_Accuracy": 0.7972972972972973,
                "Executable_Rate": 0.893581081081081,
                "Executable_Accuracy": 0.8052930056710775
            }
        },
        "FOLIO": {
            "random": {
                "Overall_Accuracy": 0.6237623762376238,
                "Executable_Rate": 0.594059405940594,
                "Executable_Accuracy": 0.825
            },
            "Direct": {
                "Overall_Accuracy": 0.7277227722772277,
                "Executable_Rate": 0.594059405940594,
                "Executable_Accuracy": 0.8333333333333334
            },
            "CoT": {
                "Overall_Accuracy": 0.8267326732673267,
                "Executable_Rate": 0.5792079207920792,
                "Executable_Accuracy": 0.8290598290598291
            }
        },
        "LogicalDeduction": {
            "random": {
                "Overall_Accuracy": 0.6033333333333334,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8722222222222222
            },
            "Direct": {
                "Overall_Accuracy": 0.7133333333333334,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8722222222222222
            },
            "CoT": {
                "Overall_Accuracy": 0.75,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8722222222222222
            }
        },
        "AR-LSAT": {
            "random": {
                "Overall_Accuracy": 0.19047619047619047,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0.30303030303030304,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0.24675324675324675,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        }
    },
    "gemini-1.5-pro-preview-0514": {
        "ProntoQA": {
            "random": {
                "Overall_Accuracy": 0.464,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0.8,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0.95,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        },
        "ProofWriter": {
            "random": {
                "Overall_Accuracy": 0.345,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0.5666666666666667,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0.6416666666666667,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        },
        "FOLIO": {
            "random": {
                "Overall_Accuracy": 0.7114427860696517,
                "Executable_Rate": 0.7711442786069652,
                "Executable_Accuracy": 0.8516129032258064
            },
            "Direct": {
                "Overall_Accuracy": 0.8159203980099502,
                "Executable_Rate": 0.7810945273631841,
                "Executable_Accuracy": 0.8535031847133758
            },
            "CoT": {
                "Overall_Accuracy": 0.8159203980099502,
                "Executable_Rate": 0.7810945273631841,
                "Executable_Accuracy": 0.8535031847133758
            }
        },
        "LogicalDeduction": {
            "random": {
                "Overall_Accuracy": 0.8466666666666667,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.8466666666666667
            },
            "Direct": {
                "Overall_Accuracy": 0.8466666666666667,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.8466666666666667
            },
            "CoT": {
                "Overall_Accuracy": 0.8466666666666667,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.8466666666666667
            }
        },
        "AR-LSAT": {
            "random": {
                "Overall_Accuracy": 0.31601731601731603,
                "Executable_Rate": 0.26406926406926406,
                "Executable_Accuracy": 0.6065573770491803
            },
            "Direct": {
                "Overall_Accuracy": 0.3852813852813853,
                "Executable_Rate": 0.26406926406926406,
                "Executable_Accuracy": 0.6065573770491803
            },
            "CoT": {
                "Overall_Accuracy": 0.31601731601731603,
                "Executable_Rate": 0.26406926406926406,
                "Executable_Accuracy": 0.6065573770491803
            }
        }
    },
    "gemini-1.5-flash-preview-0514": {
        "ProntoQA": {
            "random": {
                "Overall_Accuracy": 0.46938775510204084,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0.625,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0.9438775510204082,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        },
        "ProofWriter": {
            "random": {
                "Overall_Accuracy": 0.32166666666666666,
                "Executable_Rate": 0.04666666666666667,
                "Executable_Accuracy": 0.5357142857142857
            },
            "Direct": {
                "Overall_Accuracy": 0.5366666666666666,
                "Executable_Rate": 0.04666666666666667,
                "Executable_Accuracy": 0.5357142857142857
            },
            "CoT": {
                "Overall_Accuracy": 0.6716666666666666,
                "Executable_Rate": 0.04666666666666667,
                "Executable_Accuracy": 0.5357142857142857
            }
        },
        "FOLIO": {
            "random": {
                "Overall_Accuracy": 0.3627450980392157,
                "Executable_Rate": 0.04411764705882353,
                "Executable_Accuracy": 1.0
            },
            "Direct": {
                "Overall_Accuracy": 0.6813725490196079,
                "Executable_Rate": 0.04411764705882353,
                "Executable_Accuracy": 1.0
            },
            "CoT": {
                "Overall_Accuracy": 0.6862745098039216,
                "Executable_Rate": 0.04411764705882353,
                "Executable_Accuracy": 1.0
            }
        },
        "LogicalDeduction": {
            "random": {
                "Overall_Accuracy": 0.5633333333333334,
                "Executable_Rate": 0.7166666666666667,
                "Executable_Accuracy": 0.6976744186046512
            },
            "Direct": {
                "Overall_Accuracy": 0.5966666666666667,
                "Executable_Rate": 0.7166666666666667,
                "Executable_Accuracy": 0.6976744186046512
            },
            "CoT": {
                "Overall_Accuracy": 0.61,
                "Executable_Rate": 0.7166666666666667,
                "Executable_Accuracy": 0.6976744186046512
            }
        },
        "AR-LSAT": {
            "random": {
                "Overall_Accuracy": 0.3246753246753247,
                "Executable_Rate": 0.33766233766233766,
                "Executable_Accuracy": 0.6025641025641025
            },
            "Direct": {
                "Overall_Accuracy": 0.38095238095238093,
                "Executable_Rate": 0.33766233766233766,
                "Executable_Accuracy": 0.6025641025641025
            },
            "CoT": {
                "Overall_Accuracy": 0.3463203463203463,
                "Executable_Rate": 0.33766233766233766,
                "Executable_Accuracy": 0.6025641025641025
            }
        }
    }
}