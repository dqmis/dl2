{
    "gemini-1.0-pro-vision-001": {
        "ProntoQA": {
            "random": {
                "Overall_Accuracy": 0.774,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.774
            },
            "Direct": {
                "Overall_Accuracy": 0.774,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.774
            },
            "CoT": {
                "Overall_Accuracy": 0.774,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.774
            }
        },
        "ProofWriter": {
            "random": {
                "Overall_Accuracy": 0.6126878130217028,
                "Executable_Rate": 0.6444073455759599,
                "Executable_Accuracy": 0.7616580310880829
            },
            "Direct": {
                "Overall_Accuracy": 0.49081803005008345,
                "Executable_Rate": 0.6444073455759599,
                "Executable_Accuracy": 0.7616580310880829
            },
            "CoT": {
                "Overall_Accuracy": 0.49081803005008345,
                "Executable_Rate": 0.6444073455759599,
                "Executable_Accuracy": 0.7616580310880829
            }
        },
        "FOLIO": {
            "random": {
                "Overall_Accuracy": 0.53,
                "Executable_Rate": 0.485,
                "Executable_Accuracy": 0.6804123711340206
            },
            "Direct": {
                "Overall_Accuracy": 0.33,
                "Executable_Rate": 0.48,
                "Executable_Accuracy": 0.6875
            },
            "CoT": {
                "Overall_Accuracy": 0.33,
                "Executable_Rate": 0.485,
                "Executable_Accuracy": 0.6804123711340206
            }
        },
        "LogicalDeduction": {
            "random": {
                "Overall_Accuracy": 0.6133333333333333,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8944444444444445
            },
            "Direct": {
                "Overall_Accuracy": 0.5366666666666666,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8944444444444445
            },
            "CoT": {
                "Overall_Accuracy": 0.5366666666666666,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8944444444444445
            }
        },
        "AR-LSAT": {
            "random": {
                "Overall_Accuracy": 0.2217391304347826,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        }
    },
    "gemini-1.5-pro-preview-0409": {
        "ProntoQA": {
            "random": {
                "Overall_Accuracy": 0.956,
                "Executable_Rate": 0.964,
                "Executable_Accuracy": 0.9730290456431535
            },
            "Direct": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0.938,
                "Executable_Rate": 0.964,
                "Executable_Accuracy": 0.9730290456431535
            }
        },
        "ProofWriter": {
            "random": {
                "Overall_Accuracy": 0.7466216216216216,
                "Executable_Rate": 0.893581081081081,
                "Executable_Accuracy": 0.8052930056710775
            },
            "Direct": {
                "Overall_Accuracy": 0.7195945945945946,
                "Executable_Rate": 0.893581081081081,
                "Executable_Accuracy": 0.8052930056710775
            },
            "CoT": {
                "Overall_Accuracy": 0.7195945945945946,
                "Executable_Rate": 0.893581081081081,
                "Executable_Accuracy": 0.8052930056710775
            }
        },
        "FOLIO": {
            "random": {
                "Overall_Accuracy": 0.6237623762376238,
                "Executable_Rate": 0.594059405940594,
                "Executable_Accuracy": 0.825
            },
            "Direct": {
                "Overall_Accuracy": 0.4801980198019802,
                "Executable_Rate": 0.5792079207920792,
                "Executable_Accuracy": 0.8290598290598291
            },
            "CoT": {
                "Overall_Accuracy": 0.5,
                "Executable_Rate": 0.599009900990099,
                "Executable_Accuracy": 0.8347107438016529
            }
        },
        "LogicalDeduction": {
            "random": {
                "Overall_Accuracy": 0.6033333333333334,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8722222222222222
            },
            "Direct": {
                "Overall_Accuracy": 0.5233333333333333,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8722222222222222
            },
            "CoT": {
                "Overall_Accuracy": 0.5233333333333333,
                "Executable_Rate": 0.6,
                "Executable_Accuracy": 0.8722222222222222
            }
        },
        "AR-LSAT": {
            "random": {
                "Overall_Accuracy": 0.19047619047619047,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        }
    },
    "gemini-1.5-pro-preview-0514": {
        "ProntoQA": {
            "random": {
                "Overall_Accuracy": 0.464,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        },
        "ProofWriter": {
            "random": {
                "Overall_Accuracy": 0.345,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        },
        "FOLIO": {
            "random": {
                "Overall_Accuracy": 0.7114427860696517,
                "Executable_Rate": 0.7711442786069652,
                "Executable_Accuracy": 0.8516129032258064
            },
            "Direct": {
                "Overall_Accuracy": 0.6666666666666666,
                "Executable_Rate": 0.7810945273631841,
                "Executable_Accuracy": 0.8535031847133758
            },
            "CoT": {
                "Overall_Accuracy": 0.6567164179104478,
                "Executable_Rate": 0.7711442786069652,
                "Executable_Accuracy": 0.8516129032258064
            }
        },
        "LogicalDeduction": {
            "random": {
                "Overall_Accuracy": 0.8466666666666667,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.8466666666666667
            },
            "Direct": {
                "Overall_Accuracy": 0.8466666666666667,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.8466666666666667
            },
            "CoT": {
                "Overall_Accuracy": 0.8466666666666667,
                "Executable_Rate": 1.0,
                "Executable_Accuracy": 0.8466666666666667
            }
        },
        "AR-LSAT": {
            "random": {
                "Overall_Accuracy": 0.31601731601731603,
                "Executable_Rate": 0.26406926406926406,
                "Executable_Accuracy": 0.6065573770491803
            },
            "Direct": {
                "Overall_Accuracy": 0.16017316017316016,
                "Executable_Rate": 0.2597402597402597,
                "Executable_Accuracy": 0.6166666666666667
            },
            "CoT": {
                "Overall_Accuracy": 0.16017316017316016,
                "Executable_Rate": 0.2597402597402597,
                "Executable_Accuracy": 0.6166666666666667
            }
        }
    },
    "gemini-1.5-flash-preview-0514": {
        "ProntoQA": {
            "random": {
                "Overall_Accuracy": 0.46938775510204084,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "Direct": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            },
            "CoT": {
                "Overall_Accuracy": 0,
                "Executable_Rate": 0.0,
                "Executable_Accuracy": 0
            }
        },
        "ProofWriter": {
            "random": {
                "Overall_Accuracy": 0.32166666666666666,
                "Executable_Rate": 0.04666666666666667,
                "Executable_Accuracy": 0.5357142857142857
            },
            "Direct": {
                "Overall_Accuracy": 0.025,
                "Executable_Rate": 0.04666666666666667,
                "Executable_Accuracy": 0.5357142857142857
            },
            "CoT": {
                "Overall_Accuracy": 0.025,
                "Executable_Rate": 0.04666666666666667,
                "Executable_Accuracy": 0.5357142857142857
            }
        },
        "FOLIO": {
            "random": {
                "Overall_Accuracy": 0.3627450980392157,
                "Executable_Rate": 0.04411764705882353,
                "Executable_Accuracy": 1.0
            },
            "Direct": {
                "Overall_Accuracy": 0.04411764705882353,
                "Executable_Rate": 0.04411764705882353,
                "Executable_Accuracy": 1.0
            },
            "CoT": {
                "Overall_Accuracy": 0.04411764705882353,
                "Executable_Rate": 0.04411764705882353,
                "Executable_Accuracy": 1.0
            }
        },
        "LogicalDeduction": {
            "random": {
                "Overall_Accuracy": 0.5633333333333334,
                "Executable_Rate": 0.7166666666666667,
                "Executable_Accuracy": 0.6976744186046512
            },
            "Direct": {
                "Overall_Accuracy": 0.5,
                "Executable_Rate": 0.7166666666666667,
                "Executable_Accuracy": 0.6976744186046512
            },
            "CoT": {
                "Overall_Accuracy": 0.5,
                "Executable_Rate": 0.7166666666666667,
                "Executable_Accuracy": 0.6976744186046512
            }
        },
        "AR-LSAT": {
            "random": {
                "Overall_Accuracy": 0.3246753246753247,
                "Executable_Rate": 0.33766233766233766,
                "Executable_Accuracy": 0.6025641025641025
            },
            "Direct": {
                "Overall_Accuracy": 0.20346320346320346,
                "Executable_Rate": 0.33766233766233766,
                "Executable_Accuracy": 0.6025641025641025
            },
            "CoT": {
                "Overall_Accuracy": 0.20346320346320346,
                "Executable_Rate": 0.33766233766233766,
                "Executable_Accuracy": 0.6025641025641025
            }
        }
    }
}